{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EnTy1SEajpPV"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data.read import DataReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add answer_sep: <answer>\n",
      "Add start_sep <start>\n",
      "Add start_sep <end>\n"
     ]
    }
   ],
   "source": [
    "reader = DataReader(\n",
    "    path=\"data/public_test/\",\n",
    "    output_dir=\"data/public_test_v6\",\n",
    "    tokenizer_name=\"sberbank-ai/rugpt3xl\",\n",
    "    part=\"test\",\n",
    "    window_size=40,\n",
    "    local_rank=0,\n",
    "    word_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing files from test part on 0...: 100%|██████████| 4906/4906 [00:14<00:00, 329.46it/s]\n",
      "Making raw files...: 100%|██████████| 536/536 [00:08<00:00, 59.66it/s]\n",
      "Making raw files...: 100%|██████████| 4370/4370 [00:03<00:00, 1365.57it/s]\n"
     ]
    }
   ],
   "source": [
    "reader.prc(is_save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scs7xKdhjpPZ"
   },
   "source": [
    "### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"USE_DEEPSPEED\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.xl_wrapper import RuGPT3XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> initializing model parallel with size 1\n",
      "Use alternating sparse & dense attention layers\n",
      "> initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234\n"
     ]
    }
   ],
   "source": [
    "model = RuGPT3XL.from_pretrained(\n",
    "    model_name_or_path=\"sberbank-ai/rugpt3xl\",\n",
    "    seq_len=512,\n",
    "    weights_path=\"../models/xl/v14_130k/20000/mp_rank_00_model_states.pt\",\n",
    "    deepspeed_config_path=\"src/deepspeed_config/gpt3_xl_sparse_2048.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tokenizer = reader.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Qw65CVzjpPZ",
    "outputId": "79a31fb8-656d-4923-f208-1589d675d7c7"
   },
   "outputs": [],
   "source": [
    "def filter_results(nr):\n",
    "    return [x[:x.find(\"<|endoftext|>\")][:x.find(\"</s>\")] for x in nr]\n",
    "\n",
    "\n",
    "def generate(model, text, additional_len=32, num_beams=5, do_sample=None):\n",
    "    min_len = min(len(model.tokenizer.encode(text)), 2048 - additional_len)\n",
    "    with torch.no_grad():\n",
    "        return filter_results(model.generate(\n",
    "            text=text,\n",
    "            max_length=min_len + additional_len,\n",
    "            do_sample=do_sample,\n",
    "            num_beams=num_beams,\n",
    "            eos_token_id=model.tokenizer.eos_token_id,\n",
    "            num_return_sequences=1,\n",
    "        ))[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_prefix = reader.lm_prefixes[\"named\"][list(reader.lm_prefixes[\"named\"].keys())[1]][6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data with the following format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>человечества продемонстрировал Нюрнбергский процесс». Напомним, в пятницу и субботу в Нюрнберге пройдет международная конференция «Нюрнбергские принципы 70 лет спустя: Современные вызовы», приуроченная к 70-летию начала международного судебного процесса над нацистскими преступниками – бывшими главарями гитлеровской Германии. В работе форума, организованного<start>Международной академией нюрнбергских принципов<end>, примут участие известные юристы, историки, политики и общественные деятели из десятков стран мира. Международный трибунал, вошедший в историю как Нюрнбергский процесс, стал событием, которое явилось краеугольным камнем в конструкции современного мироустройства и легло в основу международной уголовной практики. Принципы,<answer>'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = generate(model, lm_prefix, num_beams=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Международная академия нюрнбергских принципов'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.split(reader.answer_sep)[-1].strip()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ruGPT3XL_generation",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
